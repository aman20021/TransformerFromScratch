{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"batch_size\": 8,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lr\": 10**-4,\n",
    "        \"seq_len\": 500,\n",
    "        \"d_model\": 512,\n",
    "        \"datasource\": 'opus100EnHi',\n",
    "        \"lang_src\": \"en\",\n",
    "        \"lang_tgt\": \"hi\",\n",
    "        \"model_folder\": \"weights\",\n",
    "        \"model_basename\": \"tmodel_\",\n",
    "        \"preload\": \"latest\",\n",
    "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
    "        \"experiment_name\": \"runs/tmodel\"\n",
    "    }\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_file_path(epoch: str):\n",
    "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
    "    model_filename = f\"{config['model_basename']}{epoch}.pt\"\n",
    "    return str(Path('.') / model_folder / model_filename)\n",
    "\n",
    "# Find the latest weights file in the weights folder\n",
    "def latest_weights_file_path(config):\n",
    "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
    "    model_filename = f\"{config['model_basename']}*\"\n",
    "    weights_files = list(Path(model_folder).glob(model_filename))\n",
    "    if len(weights_files) == 0:\n",
    "        return None\n",
    "    weights_files.sort()\n",
    "    return str(weights_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tokenizer_{'batch_size': 8, 'num_epochs': 20, 'lr': 0.0001, 'seq_len': 500, 'd_model': 512, 'datasource': 'opus100EnHi', 'lang_src': 'en', 'lang_tgt': 'hi', 'model_folder': 'weights', 'model_basename': 'tmodel_', 'preload': 'latest', 'tokenizer_file': 'tokenizer_{0}.json', 'experiment_name': 'runs/tmodel'}.json\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['tokenizer_file'].format(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(ds,lang):\n",
    "    for item in ds:\n",
    "        yield item['translation'][lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_build_tokenizer(ds,lang):\n",
    "    path = Path(config['tokenizer_file'].format(lang))\n",
    "\n",
    "    if not Path.exists(path):\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
    "        tokenizer.save(str(path))\n",
    "\n",
    "        tokenizer.save(str(path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(path))\n",
    "    \n",
    "    return tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BilingualDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "def get_ds():\n",
    "    ds_raw = load_dataset(\"opus100\", \"en-hi\",split='train')\n",
    "\n",
    "     # Build tokenizers\n",
    "    tokenizer_src = get_or_build_tokenizer(ds_raw, config['lang_src'])\n",
    "    tokenizer_tgt = get_or_build_tokenizer(ds_raw, config['lang_tgt'])\n",
    "\n",
    "    # Keep 90% for training, 10% for validation\n",
    "    train_ds_size = int(0.9 * len(ds_raw))\n",
    "    val_ds_size = len(ds_raw) - train_ds_size\n",
    "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
    "\n",
    "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "\n",
    "    # Find the maximum length of each sentence in the source and target sentence\n",
    "    max_len_src = 0\n",
    "    max_len_tgt = 0\n",
    "\n",
    "    for item in ds_raw:\n",
    "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
    "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
    "        max_len_src = max(max_len_src, len(src_ids))\n",
    "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "    print(f'Max length of source sentence: {max_len_src}')\n",
    "    print(f'Max length of target sentence: {max_len_tgt}')\n",
    "    \n",
    "\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 441\n",
      "Max length of target sentence: 441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2e2428520>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2e2428430>,\n",
       " <tokenizers.Tokenizer at 0x2e240d030>,\n",
       " <tokenizers.Tokenizer at 0x2e23f3c30>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 441\n",
      "Max length of target sentence: 441\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (500) must match the existing size (499) at non-singleton dimension 0.  Target sizes: [500, 256].  Tensor sizes: [499, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     model \u001b[39m=\u001b[39m build_transformer(vocab_src_len, vocab_tgt_len, config[\u001b[39m\"\u001b[39m\u001b[39mseq_len\u001b[39m\u001b[39m\"\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mseq_len\u001b[39m\u001b[39m'\u001b[39m], d_model\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39md_model\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m get_model(config, tokenizer_src\u001b[39m.\u001b[39;49mget_vocab_size(), tokenizer_tgt\u001b[39m.\u001b[39;49mget_vocab_size())\n",
      "Cell \u001b[0;32mIn[147], line 4\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(config, vocab_src_len, vocab_tgt_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m(config, vocab_src_len, vocab_tgt_len):\n\u001b[0;32m----> 4\u001b[0m     model \u001b[39m=\u001b[39m build_transformer(vocab_src_len, vocab_tgt_len, config[\u001b[39m\"\u001b[39;49m\u001b[39mseq_len\u001b[39;49m\u001b[39m\"\u001b[39;49m], config[\u001b[39m'\u001b[39;49m\u001b[39mseq_len\u001b[39;49m\u001b[39m'\u001b[39;49m], d_model\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39md_model\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/Practical Deep Learning/TransformerFromScratch/model.py:257\u001b[0m, in \u001b[0;36mbuild_transformer\u001b[0;34m(src_vocab_size, tgt_vocab_size, src_seq_len, tgt_seq_len, d_model, N, h, dropout, d_ff)\u001b[0m\n\u001b[1;32m    254\u001b[0m tgt_embed \u001b[39m=\u001b[39m InputEmbeddings(d_model, tgt_vocab_size)\n\u001b[1;32m    256\u001b[0m \u001b[39m# Create the positional encoding layers\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m src_pos \u001b[39m=\u001b[39m PositionalEncoding(d_model, src_seq_len, dropout)\n\u001b[1;32m    258\u001b[0m tgt_pos \u001b[39m=\u001b[39m PositionalEncoding(d_model, tgt_seq_len, dropout)\n\u001b[1;32m    260\u001b[0m \u001b[39m# Create the encoder blocks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Practical Deep Learning/TransformerFromScratch/model.py:35\u001b[0m, in \u001b[0;36mPositionalEncoding.__init__\u001b[0;34m(self, d_model, seq_len, dropout)\u001b[0m\n\u001b[1;32m     32\u001b[0m div_term \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, d_model, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mfloat() \u001b[39m*\u001b[39m (\u001b[39m-\u001b[39mmath\u001b[39m.\u001b[39mlog(\u001b[39m10000.0\u001b[39m) \u001b[39m/\u001b[39m d_model)) \u001b[39m# (d_model / 2)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Apply sine to even indices\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m pe[:, \u001b[39m0\u001b[39;49m::\u001b[39m2\u001b[39;49m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msin(position \u001b[39m*\u001b[39m div_term) \u001b[39m# sin(position * (10000 ** (2i / d_model))\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# Apply cosine to odd indices\u001b[39;00m\n\u001b[1;32m     37\u001b[0m pe[:, \u001b[39m1\u001b[39m::\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcos(position \u001b[39m*\u001b[39m div_term) \u001b[39m# cos(position * (10000 ** (2i / d_model))\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (500) must match the existing size (499) at non-singleton dimension 0.  Target sizes: [500, 256].  Tensor sizes: [499, 256]"
     ]
    }
   ],
   "source": [
    "from model import build_transformer\n",
    "\n",
    "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
    "    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/74/c7xsvv912v749528krt45df40000gn/T/ipykernel_39905/3778606649.py:5: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Device name: <mps>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 91\u001b[0m\n\u001b[1;32m     81\u001b[0m         model_filename \u001b[39m=\u001b[39m get_weights_file_path(config, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m02d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m         torch\u001b[39m.\u001b[39msave({\n\u001b[1;32m     83\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch,\n\u001b[1;32m     84\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m: model\u001b[39m.\u001b[39mstate_dict(),\n\u001b[1;32m     85\u001b[0m             \u001b[39m'\u001b[39m\u001b[39moptimizer_state_dict\u001b[39m\u001b[39m'\u001b[39m: optimizer\u001b[39m.\u001b[39mstate_dict(),\n\u001b[1;32m     86\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mglobal_step\u001b[39m\u001b[39m'\u001b[39m: global_step\n\u001b[1;32m     87\u001b[0m         }, model_filename)\n\u001b[0;32m---> 91\u001b[0m train_model()\n",
      "Cell \u001b[0;32mIn[129], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Make sure the weights folder exists\u001b[39;00m\n\u001b[1;32m     19\u001b[0m Path(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconfig[\u001b[39m'\u001b[39m\u001b[39mdatasource\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mconfig[\u001b[39m'\u001b[39m\u001b[39mmodel_folder\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt \u001b[39m=\u001b[39m get_ds()\n\u001b[1;32m     22\u001b[0m model \u001b[39m=\u001b[39m get_model(config, tokenizer_src\u001b[39m.\u001b[39mget_vocab_size(), tokenizer_tgt\u001b[39m.\u001b[39mget_vocab_size())\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Tensorboard\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[127], line 24\u001b[0m, in \u001b[0;36mget_ds\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m ds_raw:\n\u001b[1;32m     23\u001b[0m     src_ids \u001b[39m=\u001b[39m tokenizer_src\u001b[39m.\u001b[39mencode(item[\u001b[39m'\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m'\u001b[39m][config[\u001b[39m'\u001b[39m\u001b[39mlang_src\u001b[39m\u001b[39m'\u001b[39m]])\u001b[39m.\u001b[39mids\n\u001b[0;32m---> 24\u001b[0m     tgt_ids \u001b[39m=\u001b[39m tokenizer_tgt\u001b[39m.\u001b[39;49mencode(item[\u001b[39m'\u001b[39;49m\u001b[39mtranslation\u001b[39;49m\u001b[39m'\u001b[39;49m][config[\u001b[39m'\u001b[39;49m\u001b[39mlang_tgt\u001b[39;49m\u001b[39m'\u001b[39;49m]])\u001b[39m.\u001b[39mids\n\u001b[1;32m     25\u001b[0m     max_len_src \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(max_len_src, \u001b[39mlen\u001b[39m(src_ids))\n\u001b[1;32m     26\u001b[0m     max_len_tgt \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(max_len_tgt, \u001b[39mlen\u001b[39m(tgt_ids))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "def train_model():\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    if (device == 'cuda'):\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
    "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
    "    elif (device == 'mps'):\n",
    "        print(f\"Device name: <mps>\")\n",
    "    else:\n",
    "        print(\"NOTE: If you have a GPU, consider using it for training.\")\n",
    "        print(\"      On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\")\n",
    "        print(\"      On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\")\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Make sure the weights folder exists\n",
    "    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds()\n",
    "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "    # Tensorboard\n",
    "    writer = SummaryWriter(config['experiment_name'])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    global_step = 0\n",
    "    preload = config['preload']\n",
    "    model_filename = latest_weights_file_path() if preload == 'latest' else get_weights_file_path(preload) if preload else None\n",
    "    if model_filename:\n",
    "        print(f'Preloading model {model_filename}')\n",
    "        state = torch.load(model_filename)\n",
    "        model.load_state_dict(state['model_state_dict'])\n",
    "        initial_epoch = state['epoch'] + 1\n",
    "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "        global_step = state['global_step']\n",
    "    else:\n",
    "        print('No model to preload, starting from scratch')\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
    "\n",
    "    for epoch in range(initial_epoch, config['num_epochs']):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        for batch in batch_iterator:\n",
    "\n",
    "            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n",
    "            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
    "            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
    "            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
    "\n",
    "            # Run the tensors through the encoder, decoder and the projection layer\n",
    "            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
    "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
    "            proj_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n",
    "\n",
    "            # Compare the output with the label\n",
    "            label = batch['label'].to(device) # (B, seq_len)\n",
    "\n",
    "            # Compute the loss using a simple cross entropy\n",
    "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "\n",
    "            # Log the loss\n",
    "            writer.add_scalar('train loss', loss.item(), global_step)\n",
    "            writer.flush()\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        # Save the model at the end of every epoch\n",
    "        model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'global_step': global_step\n",
    "        }, model_filename)\n",
    "\n",
    "\n",
    "\n",
    "train_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
